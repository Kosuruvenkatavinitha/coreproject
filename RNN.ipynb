{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z_KKoxPdAYIQAiHhaooKFHtf5wOU9_0T",
      "authorship_tag": "ABX9TyMLEvEuT+JbtnkQfePl9GeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kosuruvenkatavinitha/coreproject/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Load your CSV dataset\n",
        "# Assuming you have a 'label' column indicating normal (0) or anomaly (1)\n",
        "df = pd.read_csv('/content/predictive_maintenance.csv')\n",
        "\n",
        "# Drop non-numeric columns for simplicity\n",
        "df_numeric = df.drop(['Product ID', 'Type', 'Failure Type'], axis=1)\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df_numeric.iloc[:, :-1].values\n",
        "y = df_numeric.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (you can choose a scaler)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a simple RNN model\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(32, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data to fit the RNN input shape\n",
        "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Train the RNN model\n",
        "model.fit(X_train_rnn, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predictions with the RNN model\n",
        "y_rnn_pred = (model.predict(X_test_rnn) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate RNN\n",
        "print(\"\\nRNN Results:\")\n",
        "print(\"Accuracy (RNN):\", accuracy_score(y_test, y_rnn_pred))\n",
        "print(\"Classification Report (RNN):\\n\", classification_report(y_test, y_rnn_pred))\n"
      ],
      "metadata": {
        "id": "hZ80Pwna-D8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be181497-48cb-4962-bf7b-2367cd97c331"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 5s 7ms/step - loss: 0.2070 - accuracy: 0.9450\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9672\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9686\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0895 - accuracy: 0.9704\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0878 - accuracy: 0.9696\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0802 - accuracy: 0.9719\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0784 - accuracy: 0.9731\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0772 - accuracy: 0.9747\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9745\n",
            "63/63 [==============================] - 0s 3ms/step\n",
            "\n",
            "RNN Results:\n",
            "Accuracy (RNN): 0.968\n",
            "Classification Report (RNN):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98      1939\n",
            "           1       0.48      0.54      0.51        61\n",
            "\n",
            "    accuracy                           0.97      2000\n",
            "   macro avg       0.73      0.76      0.75      2000\n",
            "weighted avg       0.97      0.97      0.97      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Load your dataset and prepare the features (X) and labels (y)\n",
        "df = pd.read_csv('/content/predictive_maintenance.csv')\n",
        "\n",
        "# Drop non-numeric columns for simplicity\n",
        "df_numeric = df.drop(['Product ID', 'Type', 'Failure Type'], axis=1)\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df_numeric.iloc[:, :-1].values\n",
        "y = df_numeric.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values (optional but often recommended for ANNs)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN input (assuming a sequence length of 1 for simplicity)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "# Create and compile the RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(SimpleRNN(units=64, activation='relu', input_shape=(1, X_train.shape[2])))\n",
        "rnn_model.add(Dense(units=64, activation='relu'))\n",
        "rnn_model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the RNN model with 20 epochs\n",
        "rnn_model.fit(X_train, y_train, epochs=20, batch_size=32)  # 20 epochs\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Recurrent Neural Network Model Results:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4uiKqjXWw4I",
        "outputId": "ddf10440-3ce5-4ed9-9422-0ac732084bfc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 3s 3ms/step - loss: 0.1753 - accuracy: 0.9651\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9672\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9696\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9696\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9726\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9722\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9755\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0670 - accuracy: 0.9765\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9771\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9783\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9791\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9805\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9786\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9811\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9816\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9811\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9834\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.9837\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9821\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9834\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Recurrent Neural Network Model Results:\n",
            "Accuracy: 0.9815\n",
            "Precision: 0.7608695652173914\n",
            "F1 Score: 0.6542056074766355\n",
            "Recall: 0.5737704918032787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load your dataset and prepare the features (X) and labels (y)\n",
        "df = pd.read_csv('/content/predictive_maintenance.csv')\n",
        "\n",
        "# Drop non-numeric columns for simplicity\n",
        "df_numeric = df.drop(['Product ID', 'Type', 'Failure Type'], axis=1)\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df_numeric.iloc[:, :-1].values\n",
        "y = df_numeric.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values (optional but often recommended for ANNs)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN input (assuming a sequence length of 1 for simplicity)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "# Create and compile the RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(SimpleRNN(units=64, activation='relu', input_shape=(1, X_train.shape[2])))\n",
        "rnn_model.add(Dense(units=64, activation='relu'))\n",
        "rnn_model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define an Early Stopping callback to monitor the validation loss and stop training when it doesn't improve\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the RNN model with early stopping\n",
        "rnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stopping], batch_size=32)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = (rnn_model.predict(X_test) > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Recurrent Neural Network Model Results:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgWPwzHThfm2",
        "outputId": "adb835dd-d9df-4fde-8870-ccff87d70374"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 2s 4ms/step - loss: 0.1691 - accuracy: 0.9644 - val_loss: 0.1060 - val_accuracy: 0.9730\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Recurrent Neural Network Model Results:\n",
            "Accuracy: 0.973\n",
            "Precision: 0.7333333333333333\n",
            "F1 Score: 0.2894736842105263\n",
            "Recall: 0.18032786885245902\n"
          ]
        }
      ]
    }
  ]
}